{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SoZMmaS-RHVA"
   },
   "source": [
    "# Fine-tuning Wav2Vec2 for Amharic Legal ASR with LoRA\n",
    "\n",
    "This notebook fine-tunes `agkphysics/wav2vec2-large-xlsr-53-amharic` for legal domain Amharic speech recognition using LoRA (Low-Rank Adaptation) for efficient training on Colab free tier.\n",
    "\n",
    "## Model and Approach\n",
    "- **Base Model**: `agkphysics/wav2vec2-large-xlsr-53-amharic`\n",
    "- **Fine-tuning Method**: LoRA (via PEFT library)\n",
    "- **Task**: Automatic Speech Recognition (ASR)\n",
    "- **Domain**: Legal Amharic text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DBs0OtVRHVN"
   },
   "source": [
    "## 1. Installation and Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oA0TIzXYRHVO",
    "outputId": "309eae94-d728-43cd-b314-fd4cd422c695"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "%pip install -q transformers datasets accelerate peft torchaudio librosa jiwer soundfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KiAJxozFRHVQ",
    "outputId": "ae85b213-d346-4cde-dd72-7dc64b2910a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0+cu126\n",
      "CUDA available: True\n",
      "CUDA device: Tesla T4\n",
      "CUDA memory: 15.83 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Union, Optional\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from transformers import (\n",
    "    Wav2Vec2Processor,\n",
    "    Wav2Vec2ForCTC,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    Wav2Vec2CTCTokenizer,\n",
    "    Wav2Vec2FeatureExtractor,\n",
    "    Wav2Vec2Processor\n",
    ")\n",
    "\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    TaskType\n",
    ")\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "import jiwer\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rfSjXrKbSAY3",
    "outputId": "35f096ea-9362-4f40-d593-d3ac6f1abee2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtdlWzztRHVS"
   },
   "source": [
    "## 2. Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4HRLhSmZRHVT",
    "outputId": "00ad00d8-395b-477d-cfa5-78c1e508c098"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Model: agkphysics/wav2vec2-large-xlsr-53-amharic\n",
      "  Output directory: wav2vec2_lora_amharic_legal\n",
      "  LoRA rank (r): 8\n",
      "  LoRA alpha: 32\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"agkphysics/wav2vec2-large-xlsr-53-amharic\"\n",
    "\n",
    "AUDIO_DIR = \"/content/drive/MyDrive/Dataset_1.5h/audio\"\n",
    "TRAIN_CSV = \"/content/drive/MyDrive/Dataset_1.5h/train.csv\"\n",
    "VAL_CSV = \"/content/drive/MyDrive/Dataset_1.5h/val.csv\"\n",
    "TEST_CSV = \"/content/drive/MyDrive/Dataset_1.5h/test.csv\"\n",
    "\n",
    "OUTPUT_DIR = \"wav2vec2_lora_amharic_legal\"\n",
    "\n",
    "LORA_CONFIG = {\n",
    "    \"r\": 8,\n",
    "    \"lora_alpha\": 32,\n",
    "    \"target_modules\": [\"q_proj\", \"v_proj\", \"k_proj\", \"out_proj\"],\n",
    "    \"lora_dropout\": 0.1,\n",
    "    \"bias\": \"none\",\n",
    "    \"task_type\": \"FEATURE_EXTRACTION\"\n",
    "}\n",
    "\n",
    "TRAINING_ARGS = {\n",
    "    \"output_dir\": OUTPUT_DIR,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"per_device_eval_batch_size\": 4,\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"learning_rate\": 3e-4,\n",
    "    \"warmup_steps\": 500,\n",
    "    \"max_steps\": 5000,\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \"fp16\": True,\n",
    "    \"eval_strategy\": \"steps\",\n",
    "    \"eval_steps\": 500,\n",
    "    \"save_strategy\": \"steps\",\n",
    "    \"save_steps\": 500,\n",
    "    \"save_total_limit\": 3,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"metric_for_best_model\": \"wer\",\n",
    "    \"greater_is_better\": False,\n",
    "    \"logging_steps\": 100,\n",
    "    \"report_to\": \"none\",\n",
    "    \"push_to_hub\": False\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Model: {MODEL_NAME}\")\n",
    "print(f\"  Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"  LoRA rank (r): {LORA_CONFIG['r']}\")\n",
    "print(f\"  LoRA alpha: {LORA_CONFIG['lora_alpha']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SEkOVMoRHVU"
   },
   "source": [
    "## 3. Load and Prepare Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kk1eD9YSRHVV",
    "outputId": "84a466f9-2b0a-433a-a1ff-f6d361e0c37d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 302\n",
      "Validation samples: 37\n",
      "Test samples: 39\n",
      "\n",
      "Total samples: 378\n"
     ]
    }
   ],
   "source": [
    "def load_csv_split(csv_path, audio_dir):\n",
    "    \"\"\"Load a CSV split and return list of (audio_path, transcription) tuples\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    data = []\n",
    "    for _, row in df.iterrows():\n",
    "        audio_path = Path(audio_dir) / row['file_name']\n",
    "        transcription = str(row['transcription']).strip()\n",
    "\n",
    "        if audio_path.exists():\n",
    "            data.append({\n",
    "                'audio_path': str(audio_path),\n",
    "                'transcription': transcription\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Warning: Audio file not found: {audio_path}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "train_data = load_csv_split(TRAIN_CSV, AUDIO_DIR)\n",
    "val_data = load_csv_split(VAL_CSV, AUDIO_DIR)\n",
    "test_data = load_csv_split(TEST_CSV, AUDIO_DIR)\n",
    "\n",
    "print(f\"Train samples: {len(train_data)}\")\n",
    "print(f\"Validation samples: {len(val_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")\n",
    "print(f\"\\nTotal samples: {len(train_data) + len(val_data) + len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YX4M4CVLRHVW"
   },
   "source": [
    "## 4. Create Vocabulary and Processor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qW2cL0xRRHVY",
    "outputId": "268f5b2d-4d6d-40ca-e1a4-975873d155b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 170\n",
      "First 20 characters: [' ', 'ሀ', 'ሁ', 'ሂ', 'ሃ', 'ሄ', 'ህ', 'ሆ', 'ለ', 'ሉ', 'ሊ', 'ላ', 'ሌ', 'ል', 'ሎ', 'መ', 'ሙ', 'ሚ', 'ማ', 'ሜ']\n"
     ]
    }
   ],
   "source": [
    "def extract_vocab_from_transcriptions(data_list):\n",
    "    \"\"\"Extract unique characters from all transcriptions\"\"\"\n",
    "    vocab = set()\n",
    "    for item in data_list:\n",
    "        vocab.update(item['transcription'])\n",
    "    return sorted(list(vocab))\n",
    "\n",
    "vocab = extract_vocab_from_transcriptions(train_data + val_data + test_data)\n",
    "vocab_dict = {v: k for k, v in enumerate(vocab)}\n",
    "vocab_dict[\"|\"] = vocab_dict[\"<unk>\"] = len(vocab_dict)\n",
    "vocab_dict[\"<pad>\"] = len(vocab_dict)\n",
    "\n",
    "vocab_file = \"vocab.json\"\n",
    "with open(vocab_file, 'w', encoding='utf-8') as f:\n",
    "    import json\n",
    "    json.dump(vocab_dict, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Vocabulary size: {len(vocab_dict)}\")\n",
    "print(f\"First 20 characters: {list(vocab_dict.keys())[:20]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hga5SKM4RHVZ",
    "outputId": "4c63aba5-f29d-4d6c-aaef-ff167b6e1d46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor created successfully\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Wav2Vec2CTCTokenizer(\n",
    "    vocab_file,\n",
    "    unk_token=\"<unk>\",\n",
    "    pad_token=\"<pad>\",\n",
    "    word_delimiter_token=\"|\"\n",
    ")\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(\n",
    "    feature_size=1,\n",
    "    sampling_rate=16000,\n",
    "    padding_value=0.0,\n",
    "    do_normalize=True,\n",
    "    return_attention_mask=True\n",
    ")\n",
    "\n",
    "processor = Wav2Vec2Processor(\n",
    "    feature_extractor=feature_extractor,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(\"Processor created successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8XvLtU4RHVa"
   },
   "source": [
    "## 5. Load Model and Apply LoRA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yE9J73VPRHVb",
    "outputId": "311794d0-3bbc-4ff4-b210-835dc05244c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at agkphysics/wav2vec2-large-xlsr-53-amharic and are newly initialized because the shapes did not match:\n",
      "- lm_head.bias: found shape torch.Size([234]) in the checkpoint and torch.Size([172]) in the model instantiated\n",
      "- lm_head.weight: found shape torch.Size([234, 1024]) in the checkpoint and torch.Size([172, 1024]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model loaded: agkphysics/wav2vec2-large-xlsr-53-amharic\n",
      "Vocabulary size: 172\n",
      "Model parameters: 315.62M\n",
      "Model moved to CUDA\n"
     ]
    }
   ],
   "source": [
    "# Load model with ignore_mismatched_sizes to handle vocab size difference\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    ctc_loss_reduction=\"mean\",\n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "    vocab_size=len(processor.tokenizer),\n",
    "    ignore_mismatched_sizes=True  # This allows loading despite vocab size mismatch\n",
    ")\n",
    "\n",
    "print(f\"Base model loaded: {MODEL_NAME}\")\n",
    "print(f\"Vocabulary size: {len(processor.tokenizer)}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to(\"cuda\")\n",
    "    print(\"Model moved to CUDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "APDNpsMwRHVb",
    "outputId": "3805cc7c-2052-4ac6-d182-0cc8edc3e5c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,572,864 || all params: 317,187,884 || trainable%: 0.4959\n",
      "\n",
      "LoRA adapters applied successfully\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=LORA_CONFIG[\"r\"],\n",
    "    lora_alpha=LORA_CONFIG[\"lora_alpha\"],\n",
    "    target_modules=LORA_CONFIG[\"target_modules\"],\n",
    "    lora_dropout=LORA_CONFIG[\"lora_dropout\"],\n",
    "    bias=LORA_CONFIG[\"bias\"],\n",
    "    task_type=TaskType.FEATURE_EXTRACTION\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "print(\"\\nLoRA adapters applied successfully\")\n",
    "\n",
    "# Wrap forward method to filter out input_ids (PEFT adds it but Wav2Vec2ForCTC doesn't need it)\n",
    "original_forward = model.forward\n",
    "\n",
    "def filtered_forward(*args, **kwargs):\n",
    "    # Remove input_ids if present (PEFT adds it but Wav2Vec2ForCTC doesn't need it)\n",
    "    if 'input_ids' in kwargs:\n",
    "        del kwargs['input_ids']\n",
    "    return original_forward(*args, **kwargs)\n",
    "\n",
    "model.forward = filtered_forward\n",
    "print(\"Model forward method wrapped to filter input_ids\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGjPQteGRHVb"
   },
   "source": [
    "## 6. Prepare Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187,
     "referenced_widgets": [
      "45ab83e4920f4a61824587467bd9d916",
      "8f67a8b23543455a994b453fa607d37b",
      "a4e0969282354b18850dfccdbfbbe6cb",
      "ad63de4816c9460ab3b8b4af5dcedb52",
      "74dd8790fa0c44879f6d79d4ccfbf127",
      "5321793a7043439b9f29bbd69f45c44e",
      "a4f1e3f429c6493ea36f9970dbcbf6ca",
      "3ec10ca069354bbd91efd78e15f48653",
      "30781e8c4f414c8f89d443ae26e28f69",
      "fb540e41b84d4e90b4fbbdb0b40a24db",
      "c476c5971a3a44ec9b2fca32cea9497c",
      "7f07d6ac622c41b9b077085edde42130",
      "957230acff8742579236e97dc4a9f1de",
      "afb7ff5c30bf4366ab4b3279b1a6e86a",
      "f6bb0ffbc21b4550805df786a0e0d62d",
      "23ea8849907546399d07a1a399205763",
      "fbfcab045ccf4abbae894c8e433b6e31",
      "dfd13b759fee4df5b88e590ce99bd027",
      "eb98ae5f0b9141e7b2af103174743fd6",
      "368b779a005c402aa7ab92aece2190bb",
      "3bbd57d1c5614771972e37736e1f4344",
      "eeb2a231d3c14f189c9f975809dd832b",
      "123b91ab5fe949d6afce3b6ee2cf646a",
      "30b1dd3302e24b839460ba5a6909fbb9",
      "010c77aeb9924147aded38885efc6cf4",
      "7861c212edfc40f98fbe7347fd0c5199",
      "c0dfcb09b5c44586a3d203ce24f97608",
      "38fffcb2216941d3a99ba0780056156f",
      "71c27e377a5542b0b26bdadf14ed0d7f",
      "5638cd9e915f4811852580f45b5df6b7",
      "e7d6b365eb234a5f9561039709f4e4ec",
      "2a837ebba5084249b7cc7dfe488b220e",
      "a32d1ca41764499788b7c8cc434d967d"
     ]
    },
    "id": "49LM_ofyRHVb",
    "outputId": "b8bf86c4-0baf-4521-ef88-313b8a7fef6f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ab83e4920f4a61824587467bd9d916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/302 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f07d6ac622c41b9b077085edde42130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/37 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123b91ab5fe949d6afce3b6ee2cf646a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/39 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets prepared:\n",
      "  Train: 302 samples\n",
      "  Validation: 37 samples\n",
      "  Test: 39 samples\n"
     ]
    }
   ],
   "source": [
    "def speech_file_to_array_fn(path):\n",
    "    \"\"\"Load audio file and resample to 16kHz\"\"\"\n",
    "    speech_array, sampling_rate = librosa.load(path, sr=16000)\n",
    "    return speech_array\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    \"\"\"Process a batch of audio and transcriptions\"\"\"\n",
    "    audio = [speech_file_to_array_fn(path) for path in batch[\"audio_path\"]]\n",
    "\n",
    "    # Process audio - return as lists (no return_tensors)\n",
    "    audio_features = processor.feature_extractor(\n",
    "        audio,\n",
    "        sampling_rate=16000\n",
    "        # No padding, no return_tensors here - collator handles it\n",
    "    )\n",
    "    # Only store input_values, not attention_mask\n",
    "    batch[\"input_values\"] = audio_features.input_values  # This will be a list of arrays\n",
    "\n",
    "    # Process text using tokenizer directly - return as lists\n",
    "    batch[\"labels\"] = [tokenizer(transcription, add_special_tokens=False)[\"input_ids\"] for transcription in batch[\"transcription\"]]\n",
    "\n",
    "    # Make sure we're not accidentally storing attention_mask\n",
    "    if \"attention_mask\" in batch:\n",
    "        del batch[\"attention_mask\"]\n",
    "\n",
    "    return batch\n",
    "\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "val_dataset = Dataset.from_list(val_data)\n",
    "test_dataset = Dataset.from_list(test_data)\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    prepare_dataset,\n",
    "    remove_columns=train_dataset.column_names,\n",
    "    batch_size=100,\n",
    "    batched=True\n",
    ")\n",
    "\n",
    "val_dataset = val_dataset.map(\n",
    "    prepare_dataset,\n",
    "    remove_columns=val_dataset.column_names,\n",
    "    batch_size=100,\n",
    "    batched=True\n",
    ")\n",
    "\n",
    "test_dataset = test_dataset.map(\n",
    "    prepare_dataset,\n",
    "    remove_columns=test_dataset.column_names,\n",
    "    batch_size=100,\n",
    "    batched=True\n",
    ")\n",
    "\n",
    "print(\"Datasets prepared:\")\n",
    "print(f\"  Train: {len(train_dataset)} samples\")\n",
    "print(f\"  Validation: {len(val_dataset)} samples\")\n",
    "print(f\"  Test: {len(test_dataset)} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ePMnBg7URHVc"
   },
   "source": [
    "## 7. Data Collator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "do_OeZxlRHVc",
    "outputId": "af8b6029-8c35-4f87-f15c-c1e32b9a5e5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data collator created\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        import torch\n",
    "\n",
    "        # Extract input_values and labels - explicitly ignore attention_mask if present\n",
    "        input_values_list = [feature[\"input_values\"] for feature in features]\n",
    "        label_features = [feature[\"labels\"] for feature in features]\n",
    "\n",
    "        # Convert audio to tensors and pad manually\n",
    "        input_values_tensors = []\n",
    "        for iv in input_values_list:\n",
    "            if isinstance(iv, torch.Tensor):\n",
    "                input_values_tensors.append(iv)\n",
    "            elif isinstance(iv, np.ndarray):\n",
    "                input_values_tensors.append(torch.tensor(iv, dtype=torch.float32))\n",
    "            else:\n",
    "                input_values_tensors.append(torch.tensor(np.array(iv), dtype=torch.float32))\n",
    "\n",
    "        # Pad audio sequences\n",
    "        input_values = torch.nn.utils.rnn.pad_sequence(\n",
    "            input_values_tensors,\n",
    "            batch_first=True,\n",
    "            padding_value=0.0\n",
    "        )\n",
    "\n",
    "        # Pad labels manually\n",
    "        max_label_len = max(len(labels) for labels in label_features)\n",
    "        pad_token_id = self.processor.tokenizer.pad_token_id\n",
    "\n",
    "        padded_labels = []\n",
    "        for labels in label_features:\n",
    "            if isinstance(labels, torch.Tensor):\n",
    "                labels = labels.tolist()\n",
    "\n",
    "            padding_length = max_label_len - len(labels)\n",
    "            padded = labels + [pad_token_id] * padding_length\n",
    "            padded_labels.append(padded)\n",
    "\n",
    "        labels_tensor = torch.tensor(padded_labels, dtype=torch.long)\n",
    "\n",
    "        # Mask padded labels with -100\n",
    "        attention_mask_labels = (labels_tensor != pad_token_id).long()\n",
    "        labels_tensor = labels_tensor.masked_fill(attention_mask_labels.ne(1), -100)\n",
    "\n",
    "        # Return ONLY input_values and labels - explicitly create a new dict\n",
    "        batch = {}\n",
    "        batch[\"input_values\"] = input_values\n",
    "        batch[\"labels\"] = labels_tensor\n",
    "\n",
    "        # Explicitly ensure no other keys are present\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8Lx1gm2RHVd"
   },
   "source": [
    "## 8. Evaluation Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C05gDw0RRHVe",
    "outputId": "642c4520-d7bc-41dc-fcf0-497088327e98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics function created\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(pred):\n",
    "    \"\"\"Compute WER (Word Error Rate) and CER (Character Error Rate)\"\"\"\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "\n",
    "    wer = jiwer.wer(label_str, pred_str)\n",
    "    cer = jiwer.cer(label_str, pred_str)\n",
    "\n",
    "    return {\"wer\": wer, \"cer\": cer}\n",
    "\n",
    "print(\"Evaluation metrics function created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9h39rbJRHVe"
   },
   "source": [
    "## 9. Training Arguments and Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kIsrmgrVRHVf",
    "outputId": "3daeba46-cee3-4cef-b265-217439e5bec4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer initialized\n",
      "\n",
      "Training configuration:\n",
      "  Max steps: 5000\n",
      "  Batch size: 4\n",
      "  Gradient accumulation: 4\n",
      "  Effective batch size: 16\n",
      "  Learning rate: 0.0003\n",
      "  Evaluation steps: 500\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(**TRAINING_ARGS)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "print(\"Trainer initialized\")\n",
    "print(f\"\\nTraining configuration:\")\n",
    "print(f\"  Max steps: {training_args.max_steps}\")\n",
    "print(f\"  Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"  Gradient accumulation: {training_args.gradient_accumulation_steps}\")\n",
    "print(f\"  Effective batch size: {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\")\n",
    "print(f\"  Learning rate: {training_args.learning_rate}\")\n",
    "print(f\"  Evaluation steps: {training_args.eval_steps}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-o4oggy-RHVf"
   },
   "source": [
    "## 10. Train Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "-EAFlSv6RHVg",
    "outputId": "951d192d-6e1f-42ee-b919-821ce64cd140"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Wav2Vec2ForCTC.forward() got an unexpected keyword argument 'input_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3748140978.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Save final model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfinal_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{OUTPUT_DIR}_final\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2325\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2326\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2672\u001b[0m                     )\n\u001b[1;32m   2673\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2674\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2676\u001b[0m                     if (\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   4018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4019\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4020\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4022\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   4108\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_items_in_batch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4109\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4110\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4111\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4112\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast_instance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     decorate_autocast.__script_unsupported = (  # type: ignore[attr-defined]\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_peft_forward_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_peft_forward_args\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2986\u001b[0;31m                 return self.base_model(\n\u001b[0m\u001b[1;32m   2987\u001b[0m                     \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_injection_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPeftConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Wav2Vec2ForCTC.forward() got an unexpected keyword argument 'input_ids'"
     ]
    }
   ],
   "source": [
    "train_result = trainer.train()\n",
    "\n",
    "# Save final model\n",
    "final_model_path = f\"{OUTPUT_DIR}_final\"\n",
    "trainer.save_model(final_model_path)\n",
    "processor.save_pretrained(final_model_path)\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "print(f\"Training loss: {train_result.training_loss:.4f}\")\n",
    "print(f\"Final model saved to: {final_model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQUJNm5eRHVh"
   },
   "source": [
    "## 11. Zip and Copy Model to Google Drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qAwyb1zARHVi"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Zip the final model directory\n",
    "zip_filename = f\"{final_model_path}.zip\"\n",
    "print(f\"Creating zip file: {zip_filename}...\")\n",
    "\n",
    "with zipfile.ZipFile(zip_filename, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for file_path in Path(final_model_path).rglob(\"*\"):\n",
    "        if file_path.is_file():\n",
    "            # Get relative path for archive\n",
    "            arcname = file_path.relative_to(final_model_path)\n",
    "            zipf.write(file_path, arcname)\n",
    "            print(f\"  Added: {arcname}\")\n",
    "\n",
    "print(f\"\\nZip file created: {zip_filename}\")\n",
    "\n",
    "# Copy to Google Drive\n",
    "drive_dest = f\"/content/drive/MyDrive/{zip_filename}\"\n",
    "shutil.copy2(zip_filename, drive_dest)\n",
    "\n",
    "print(f\"Model zip file copied to Google Drive: {drive_dest}\")\n",
    "print(f\"\\nFile size: {Path(zip_filename).stat().st_size / (1024*1024):.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrA-9_3CRHVj"
   },
   "source": [
    "## 12. Final Evaluation on Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pZAuL4OgRHVk"
   },
   "outputs": [],
   "source": [
    "final_model_path = f\"{OUTPUT_DIR}_final\"\n",
    "trainer.save_model(final_model_path)\n",
    "processor.save_pretrained(final_model_path)\n",
    "\n",
    "print(f\"Final model saved to: {final_model_path}\")\n",
    "print(\"\\nFiles saved:\")\n",
    "print(\"  - LoRA adapters (adapter_model.bin, adapter_config.json)\")\n",
    "print(\"  - Processor (tokenizer, feature_extractor)\")\n",
    "print(\"  - Training configuration\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbojTaxzRHVl"
   },
   "source": [
    "## 13. Inference Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WNTgA1skRHVl"
   },
   "outputs": [],
   "source": [
    "def transcribe_audio(model, processor, audio_path):\n",
    "    \"\"\"Transcribe a single audio file\"\"\"\n",
    "    speech, _ = librosa.load(audio_path, sr=16000)\n",
    "\n",
    "    inputs = processor(\n",
    "        speech,\n",
    "        sampling_rate=16000,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True\n",
    "    )\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs.input_values).logits\n",
    "\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.batch_decode(predicted_ids)[0]\n",
    "\n",
    "    return transcription\n",
    "\n",
    "print(\"Inference function created\")\n",
    "print(\"\\nExample usage:\")\n",
    "print(\"  transcription = transcribe_audio(model, processor, 'path/to/audio.mp3')\")\n",
    "print(\"  print(transcription)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LB2IActjRHVl"
   },
   "source": [
    "## 14. Load Model for Inference (After Training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wuLQLT2URHVn"
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "def load_trained_model(base_model_name, adapter_path, processor_path):\n",
    "    \"\"\"Load base model and LoRA adapters\"\"\"\n",
    "    processor = Wav2Vec2Processor.from_pretrained(processor_path)\n",
    "\n",
    "    base_model = Wav2Vec2ForCTC.from_pretrained(\n",
    "        base_model_name,\n",
    "        ctc_loss_reduction=\"mean\",\n",
    "        pad_token_id=processor.tokenizer.pad_token_id,\n",
    "        vocab_size=len(processor.tokenizer)\n",
    "    )\n",
    "\n",
    "    model = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.to(\"cuda\")\n",
    "\n",
    "    model.eval()\n",
    "    return model, processor\n",
    "\n",
    "print(\"Model loading function created\")\n",
    "print(\"\\nExample usage:\")\n",
    "print(\"  model, processor = load_trained_model(\")\n",
    "print(\"      MODEL_NAME,\")\n",
    "print(f\"      '{OUTPUT_DIR}_final',\")\n",
    "print(f\"      '{OUTPUT_DIR}_final'\")\n",
    "print(\"  )\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "010c77aeb9924147aded38885efc6cf4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5638cd9e915f4811852580f45b5df6b7",
      "max": 39,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e7d6b365eb234a5f9561039709f4e4ec",
      "value": 39
     }
    },
    "123b91ab5fe949d6afce3b6ee2cf646a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_30b1dd3302e24b839460ba5a6909fbb9",
       "IPY_MODEL_010c77aeb9924147aded38885efc6cf4",
       "IPY_MODEL_7861c212edfc40f98fbe7347fd0c5199"
      ],
      "layout": "IPY_MODEL_c0dfcb09b5c44586a3d203ce24f97608"
     }
    },
    "23ea8849907546399d07a1a399205763": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a837ebba5084249b7cc7dfe488b220e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30781e8c4f414c8f89d443ae26e28f69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "30b1dd3302e24b839460ba5a6909fbb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_38fffcb2216941d3a99ba0780056156f",
      "placeholder": "​",
      "style": "IPY_MODEL_71c27e377a5542b0b26bdadf14ed0d7f",
      "value": "Map: 100%"
     }
    },
    "368b779a005c402aa7ab92aece2190bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "38fffcb2216941d3a99ba0780056156f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bbd57d1c5614771972e37736e1f4344": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ec10ca069354bbd91efd78e15f48653": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45ab83e4920f4a61824587467bd9d916": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8f67a8b23543455a994b453fa607d37b",
       "IPY_MODEL_a4e0969282354b18850dfccdbfbbe6cb",
       "IPY_MODEL_ad63de4816c9460ab3b8b4af5dcedb52"
      ],
      "layout": "IPY_MODEL_74dd8790fa0c44879f6d79d4ccfbf127"
     }
    },
    "5321793a7043439b9f29bbd69f45c44e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5638cd9e915f4811852580f45b5df6b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71c27e377a5542b0b26bdadf14ed0d7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "74dd8790fa0c44879f6d79d4ccfbf127": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7861c212edfc40f98fbe7347fd0c5199": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a837ebba5084249b7cc7dfe488b220e",
      "placeholder": "​",
      "style": "IPY_MODEL_a32d1ca41764499788b7c8cc434d967d",
      "value": " 39/39 [00:01&lt;00:00, 31.20 examples/s]"
     }
    },
    "7f07d6ac622c41b9b077085edde42130": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_957230acff8742579236e97dc4a9f1de",
       "IPY_MODEL_afb7ff5c30bf4366ab4b3279b1a6e86a",
       "IPY_MODEL_f6bb0ffbc21b4550805df786a0e0d62d"
      ],
      "layout": "IPY_MODEL_23ea8849907546399d07a1a399205763"
     }
    },
    "8f67a8b23543455a994b453fa607d37b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5321793a7043439b9f29bbd69f45c44e",
      "placeholder": "​",
      "style": "IPY_MODEL_a4f1e3f429c6493ea36f9970dbcbf6ca",
      "value": "Map: 100%"
     }
    },
    "957230acff8742579236e97dc4a9f1de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fbfcab045ccf4abbae894c8e433b6e31",
      "placeholder": "​",
      "style": "IPY_MODEL_dfd13b759fee4df5b88e590ce99bd027",
      "value": "Map: 100%"
     }
    },
    "a32d1ca41764499788b7c8cc434d967d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a4e0969282354b18850dfccdbfbbe6cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ec10ca069354bbd91efd78e15f48653",
      "max": 302,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_30781e8c4f414c8f89d443ae26e28f69",
      "value": 302
     }
    },
    "a4f1e3f429c6493ea36f9970dbcbf6ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ad63de4816c9460ab3b8b4af5dcedb52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb540e41b84d4e90b4fbbdb0b40a24db",
      "placeholder": "​",
      "style": "IPY_MODEL_c476c5971a3a44ec9b2fca32cea9497c",
      "value": " 302/302 [00:11&lt;00:00, 24.95 examples/s]"
     }
    },
    "afb7ff5c30bf4366ab4b3279b1a6e86a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb98ae5f0b9141e7b2af103174743fd6",
      "max": 37,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_368b779a005c402aa7ab92aece2190bb",
      "value": 37
     }
    },
    "c0dfcb09b5c44586a3d203ce24f97608": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c476c5971a3a44ec9b2fca32cea9497c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dfd13b759fee4df5b88e590ce99bd027": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e7d6b365eb234a5f9561039709f4e4ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "eb98ae5f0b9141e7b2af103174743fd6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eeb2a231d3c14f189c9f975809dd832b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f6bb0ffbc21b4550805df786a0e0d62d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bbd57d1c5614771972e37736e1f4344",
      "placeholder": "​",
      "style": "IPY_MODEL_eeb2a231d3c14f189c9f975809dd832b",
      "value": " 37/37 [00:00&lt;00:00, 48.17 examples/s]"
     }
    },
    "fb540e41b84d4e90b4fbbdb0b40a24db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fbfcab045ccf4abbae894c8e433b6e31": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
